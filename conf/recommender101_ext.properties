############################
############################
## THE CONFIGURATION FILE ##
############################
############################

## Complete Configuration ##



########
# Data #
########

# The class to load and parse the data, as well as the path to the data. Class can be extended to implement own behavior.
DataLoaderClass=org.recommender101.data.DefaultDataLoader:filename=data/movielens/MovieLens100kRatings.txt|density=1.0|minNumberOfRatingsPerUser=5|minNumberOfRatingsPerItem=10|sampleNUsers=100|binarizeLevel=0|unaryRatings=false
# filename: Path to the data file that the loader then reads. Default format: USER_ID\tITEM_ID\tRATING\n
# density: Decimal value between 0.0 and 1.0. 1.0 = default = off. Retain this percentage of ratings in the dataset to decrease density.
# minNumberOfRatingsPerUser: Only sample those users into the dataset that have a specified amount of ratings. -1 to turn off.
# minNumberOfRatingsPerItem: Only sample those item into the dataset that have a specified amount of ratings. -1 to turn off.
# sampleNUsers: Sample an amount of random users into the data. -1 to turn off.
# binarizeLevel: Ratings greater or equal the value are set to 1, others are set to 0. Setting the binarizeLevel to 0 turns binarization off.
# unaryRatings: Only used when binarizing. True: Remove 0-ratings. False: Keep 0-ratings

# An example for a more complex dataloader. Parses a timestamp (Format: USER_ID\tITEM_ID\tRATING\tTIMESTAMP\n) into the extra-information field of the datamodel which can hold arbitrary additional information.
#DataLoaderClass=org.recommender101.data.extensions.dataloader.DefaultDataLoaderWithTimeStamp:filename=data/movielens/MovieLens100kRatings.txt

# OPTIONAL: Set a non-default DataModel class. Implement your own if you need to manage more or different data.
# DataModelClass=org.recommender101.data.DataModel

# Set the rating scale according the parsed dataset.
GlobalSettings.minRating = 1
GlobalSettings.maxRating = 5

# Specify the minimum rating that will be considered a hit.
GlobalSettings.listMetricsRelevanceMinRating = 5
# ALTERNATIVE: Specify the relevance threshold on a relative per user basis.
# If no relevance rating is specified, 0% above average is used.
#GlobalSettings.listMetricsRelevanceMinPercentageAboveAverage = 20

# The class to split the data into train and test splits. It must implement the DataSplitterInterface.
DataSplitterClass=org.recommender101.data.DefaultDataSplitter:nbFolds=5|globalRandomSplit=false
# nbFolds: The default behavior is n-fold cross-validation. The data is split in n splits.
# globalRandomSplit: false (defaults) splits the ratings for each user. true splits the ratings over the whole dataset

# An example of how to split the data based on time stamps with a more complex data splitter.
#DataSplitterClass=org.recommender101.extensions.datasplitter.TimeBasedDataSplitter:testPercentage=80
# testPercentage: Percentage of (time-sorted) ratings per user that go into the training set; the rest goes into the testset

# Set the evaluation type. The default CrossValidation, for example for the DefaultDataSplitter.
EvaluationType=CrossValidation
# Use this one with your own data loader and splitter (e.g., the time-based examples above). The splitter has to create exactly two splits: A training split and a test split.
#EvaluationType=GivenTrainTestSplit

# Set a given-N configuration with N/percentage as a parameter
# N: Keep only N ratings of the user in training data
# percentage: The percentage of users for whom the given-N situation should apply
#GlobalSettings.givenNConfiguration=10/80



##############
# Algorithms #
##############

# List the algorithms that should be evaluated. They must extend the AbstractRecommender class.
# Parameters can be set as arguments. If an argument is missing, a default value is used.
AlgorithmClasses=\
org.recommender101.recommender.baseline.Random:hideKnownItems=false,\
org.recommender101.recommender.baseline.PopularityAndAverage:userAverage=false|useItemAveragesForRecommendation=false|hideKnownItems=true,\
org.recommender101.recommender.baseline.NearestNeighbors:itemBased=false|neighbors=50|minNeighbors=1|minSimilarity=0.0|minOverlap=3|similarityMetric=Jaccard,\
org.recommender101.recommender.extensions.weightedavg.WeightedAverageRecommender,\
org.recommender101.recommender.extensions.slopeone.SlopeOneRecommender,\
org.recommender101.recommender.extensions.rfrec.RfRecRecommender,\
org.recommender101.recommender.extensions.funksvd.FunkSVDRecommender:numFeatures=50|initialSteps=50,\
org.recommender101.recommender.extensions.bprmf.BPRMFRecommender:initialSteps=100|numFeatures=100|uniformSampling=true|learnRate=0.05|biasReg=0|regI=0.0025|regJ=0.00025|regU=0.0025|updateJ=true,\
org.recommender101.recommender.extensions.jfm.LibFmRecommender:initStdev=0.3|learnRates=0.03|method=3|numIter=50|regular=15|taskType=0|dim=1#1#8|verbose=false,\
org.recommender101.recommender.extensions.contentbased.ContentBasedRecommender:dataDirectory=data/movielens/|fallBack=FunkSVD|featureWeightFile=tf-idf-vectors.txt|minSimilarityForPrediction=0|nbNeighborsForPrediction=10|wordListFile=wordlist.txt,\
org.recommender101.recommender.extensions.asymmetricsvd.AsymmetricSVDRecommender:nbFactors=100|lambda=0.04|gamma=0.002|iterations=100,\
org.recommender101.recommender.extensions.mahout.RatingSGDRecommender:numFeatures=50|learningRate=0.01|preventOverfitting=0.1|randomNoise=0.01|numIterations=50|learningRateDecay=1.0,\
org.recommender101.recommender.extensions.mahout.SVDPlusPlusRecommender:numFeatures=50|learningRate=0.002|preventOverfitting=0.04|randomNoise=0.01|numIterations=50|learningRateDecay=1.0,\
org.recommender101.recommender.extensions.mahout.ParallelSGDRecommender:numFeatures=50|learningRate=0.01|preventOverfitting=0.1|randomNoise=0.01|numIterations=50|biasMuRatio=0.5|biasLambdaRatio=0.1|forgettingExponent=0|stepOffset=0|numThreads=1,\

# Random: A demo recommender which recommendens random items 
#	hideKnownItems: Do not place already rated items in the recommendation list.

# PopularityAndAverage: A demo recommender which uses the average item rating for rating prediction and the number of ratings for list generation.
#	userAverage: Use the average user rating instead of the average item rating for rating prediction.
#	useItemAveragesForRecommendation: Use the items average rating for sorting the recommendation list instead of the number of ratings.
#	hideKnownItems: Do not place already rated items in the recommendation list.

# NearestNeighbors: Implements the most common baseline. A nearest neighbor method (user/user, item/item) with Pearson correlation, Cosine similarity, or Jaccard similarity as a metric.
#	itemBased: true uses Item-KNN, false uses User-KNN.
#	neighbors: Number of neighbors to be considered (default 50)
#	minNeighbors: Minimum number of neighbors to even start predicting a similarity (default 1)
#	minSimilarity: The minimum similarity threshold (default 0.0)
#	minOverlap: The minimum overlap of co-rated items (default 3)
#	similarityMetric: The similarity metric used to find the nearest neighbors; can be either "Jaccard", "Cosine", or "Pearson" (default Jaccard)

# WeightedAverageRecommender: An algorithm which calculates a weighted combination of user and item

# SlopeOneRecommender: A weighted slope one recommender. Uses the original implementation of Daniel Lemire (lemire.me/fr/documents/publications/SlopeOne.java)

# RfRecRecommender: Implements the weighted Rf-Rec scheme as proposed in Gedikli, F., Bagdat, F., Ge, M., Jannach, D.: RF-Rec: Fast and Accurate Computation of Recommendations based on Rating Frequencies, IEEE (CEC) 2011, Luxembourg, 2011, pp. 50-57.

# FunkSVDRecommender: Implements a baseline SVD recommender, http://sifter.org/~simon/journal/20061211.html, Adapted from previous Apache Mahout implementation (0.4)
#	numFeatures: Number of factors in the factorization process (default 50)
#	initialSteps: Number of training iterations (default 50)

# BPRMFRecommender: Bayesian Personalized Ranking - Ranking by pairwise classification; matrix factorization version
#	initialSteps: Number of training iterations (default 100)
#	numFeatures: Number of factors in the factorization process (default 100)
#	uniformSampling: When learning true performs a convergence-heuristic to save runtime, false runs over all user/item-combinations (default true)
#	learnRate: Internal parameter (default 0.05)
#	biasReg: Internal parameter (default 0)
#	regI: Internal parameter (default 0.0025)
#	regJ: Internal parameter (default 0.00025)
#	regU: Internal parameter (default 0.0025)
#	updateJ: Internal parameter (default true)

# LibFmRecommender:
#	method: Choose the optimization strategy
#		0: stochastic gradient descent
#		1: adaptive stochastic gradient descent (default)
#		2: markov chain monte carlo
#		3: alternating least squares
#	learnRates: For method 0 and 1 (default 0.01)
#	regular: For method 0 and 3 (default 0#0#0)
#	initStdev: Standard deviation for the initial distribution of the factor values (default 0.1)
#	numIter: Number of training iterations (default 100)
#	dim: Dimension of factors: Use global bias (0/1), weight one-way interactions (0/1), number of factors used for the two-way interactions (>= 0) (default 1#1#8)
#	contextEnabled: Enables context usage (default true)
#	contextSourceForTestData: Manually set context data. Fully qualified name of a globally visible static HashMap<int, HashMap<int, int[]>
#	doMultilevel: Enables multilevel (default true)
#	doSampling Enables sampling (default true)
#	evalCases: Number of EvalCases for the learning algorithm (default 100)
#	taskType: Task Type. 0 = Regression (default), 1 = Classification
#	verbose: Enables verbose logging (default false)

# ContentBasedRecommender: A basic content-based recommender which calculates a user's profile based on the previously liked items and recommends items which are similar to the profile.
#	dataDirectory: Path to a word list and a TF-IDF-vector file for the dataset (see example)
#	featureWeightFile: Filename of the TF-IDF-vector file (default tf-idf-vectors.txt)
#	wordListFile: Filename of the word list file (default wordlist.txt)
#	fallBack: If there is no user profile use a fallback recommender (none by default; values: FunkSVD, SlopeOne, PopRank)
#	minSimilarityForPrediction: Threshold for similarity (default 0.0)
#	nbNeighborsForPrediction: Threshold for number of neighbors (default 10)
# 	A test for content-based recommendation:
#		Run the class org.recommender101.data.extensions.contentbaseddemo.MovieLens10MDataPreparator first to download a larger data set and to prepare TF-IDF-vectors for the experiments
#		Possible settings for content-based recommendation:
#		DataLoaderClass=org.recommender101.data.DefaultDataLoader:filename=data/movielens/MovieLens5MRatings.txt|sampleNUsers=100
#		AlgorithmClasses=	org.recommender101.recommender.extensions.contentbased.ContentBasedRecommender:dataDirectory=data/movielens|NbNeighborsForPrediction=10					 
				 	    
# AsymmetricSVDRecommender A class that implements Koren's factorized neighborhood algorithm (item-item version); more formally known as Asymmetric SVD
#	lambda: Regularization to prevent overfitting (default 0.04)
#	gamma: Learn rate (default 0.002)
#	iterations: Number of training iterations (default 100)
#	nbFactors: Number of factors in the factorization process (default 50)

# RatingSGDRecommender A matrix factorization approach taken from Apache Mahout that incorporates item and user biases
#	numFeatures: Number of factors in the factorization process (default 50)
#	numIterations: Number of training iterations (default 50)
#	learningRate: The learning rate (default 0.01)
#	preventOverfitting: Regularization to prevent overfitting (default 0.1)
#	randomNoise: Random spread for the initial distribution of the factor values (default 0.01)
#	learningRateDecay: A decay factor that decreases the learning rate each iteration; 1.0 will give you no decay (defaul 1.0)

# SVDPlusPlusRecommender A class taken from Apache Mahout that implements Koren's SVD++ algorithm (caution: not very efficiently implemented, therefore rather slow)
#	same parameters as RatingSGDRecommender but defaults are different
#	learningRate: (default 0.002)
#	preventOverfitting: (default 0.04)

# ParallelSGDRecommender A matrix factorization approach taken from Apache Mahout that works comparable to RatingSGDRecommender but parallelized 
#	same parameters as RatingSGDRecommender and additionally:
# 	numThreads: The number of threads for this algorithm (default is based on number of processors the current machine has)
#	biasMuRatio: Internal parameter (default 0.5)
#	biasLambdaRatio: Internal parameter (default 0.1)
#	forgettingExponent: Internal parameter (default 0)
#	stepOffset: Internal parameter (default 0) 


###########
# Metrics #
###########

# Specify the global setting for top-N that will be used by, e.g., precision and recall
# It can be set individually for each metric as an argument
GlobalSettings.topN = 10

# List the metrics to be measured. They must implement either the PredictionEvaluator or RecommendationListEvaluator interface
Metrics =\
org.recommender101.eval.metrics.MAE,\
org.recommender101.eval.metrics.RMSE,\
org.recommender101.eval.metrics.Precision:targetSet=allintestset|topN=10,\
org.recommender101.eval.metrics.Recall:targetSet=allintestset|topN=10,\
org.recommender101.eval.metrics.Precision:targetSet=allrelevantintestset|topN=10,\
org.recommender101.eval.metrics.Recall:targetSet=allrelevantintestset|topN=10,\
org.recommender101.eval.metrics.F1:targetSet=allintestset|topN=10,\
org.recommender101.eval.metrics.MAP:targetSet=allintestset|topN=10,\
org.recommender101.eval.metrics.FCP,\
org.recommender101.eval.metrics.MRR:topN=10,\
org.recommender101.eval.metrics.NDCG:topN=10,\
org.recommender101.eval.metrics.ROCAUC,\
org.recommender101.eval.metrics.PredictionCoverage,\
org.recommender101.eval.metrics.UserCoverage,\
org.recommender101.eval.metrics.extensions.AverageItemPopularityOfRecommendations:mode=all|topN=10|useAverageRating=false|useMedian=false,\
org.recommender101.eval.metrics.extensions.NumberOfRecommendedItems:mode=all|topN=10,\
org.recommender101.eval.metrics.extensions.Gini:mode=recommended|itemsPerBin=20|normalized=false|onlyRelevant=false|outputDir=/|topN=10

# MAE: Mean Absolute Error

# RMSE: Root-mean-square error

# Precision: Number of relevant recommended items / number of all recommended items
# Recall: Number of relevant recommended items / number of all relevant
# F1: 2*(Precision*Recall)/(Precision+Recall)
#  for all 3:
#	targetSet: set the measurement mode of the metric
#		allintestset: non-rated items in the testset are interpreted as non-relevant
#		allrelevantintestset: non-rated items in the testset are ignored
#		positioninrandomset: only for Precision and Recall. Mix 1 relevant item into a number of unrelevant items. Sort by the recommendation list. If the relecant item is among the topN it is a hit.
#	topN: set the topN value; overrides the global setting
#	nbRandomElements: sets the number of random elements for the third targetSet mode (default 100)

# MAP: Mean Average Precision @ n
#	targetSet: set the measurement mode of the metric
#		allintestset: non-rated items in the testset are interpreted as non-relevant
#		allrelevantintestset: non-rated items in the testset are ignored
#	topN: set the topN value; overrides the global setting

# MRR: Mean Reciprocal Rank
#	topN: set the topN value; overrides the global setting

# NDCG: normalized discounted cumulative gain
#	topN: set the topN value; overrides the global setting

# FCP: Fraction of Concordant Pairs

# ROCAUC: Area Under Curve of the Receiver Operating Characteristic curve

# PredictionCoverage: Number of ratings in the test that for which a prediction could be made.

# UserCoverage: Number of users for whom a prediction could be made.

# AverageItemPopularityOfRecommendations
#	mode: onlyrelevant: only consider relevant item; all: consider all items (default)
#	topN: set the topN value; overrides the global setting
#	useAverageRating: false uses number of ratings as popularity, true uses average rating as popularity (default false)
#	useMedian: true uses median instead of average for the average popularity per user (default false)

# NumberOfRecommendedItems
#	mode: onlyrelevant: only consider relevant item; all: consider all items (default)
#	topN: set the topN value; overrides the global setting

# Gini
#	mode: Sets the evaluation mode
#		recommended: group by the action number of recommendations per item (default)
#		bypopularity: group by the popularity of the item (number of ratings) in the training set
#		byavgrating: group by the average rating of the items in the traing set
#	itemsPerBin: number of items per bin for the grouping (default 20)
#	normalized: Normalize the Gini to [0;1] instead of [0;1-1/n] (default false)
#	onlyRelevant: true: only consider relevant item; false: consider all items (default)
#	outputDir: set an output directory for the verbose output of the Gini calculations
#	topN: set the topN value; overrides the global setting



###################
# Global settings #
###################

# Set a title for the experiment
ExperimentTitle=Experiment results

# Number of threads to use
# (Recommended: One thread for every (virtual) CPU core available)
GlobalSettings.numOfThreads = 4 

#Number of decimal places for metric results
GlobalSettings.outputDecimalPlaces=4

# Specify the path for a CSV output of the metric's results
CSVOutputPath=output.csv

# Specify the path for a detailed CSV output of the metric's results for each split
CSVDetailedOutputPath=output-detailed.csv

# Specify the path for a CSV output of the running times of each algorithm
CSVRuntimeOutputPath=output-runningtimes.csv

# Specify whether the output CSV should be written over for each run (new) or if the new results should be appended (append)
CSVOutputMode=new

# Give the maximum number of rounds to run the evaluation (-1 = off) 
Debug.MaxValidationRounds=1

# Stop after n predictions (debug) for prediction based metrics (-1 = off)
Debug.MaxRatingPredictions=-1
# Stop after n recommendations in list-based metrics (-1 = off)
Debug.MaxRecommendations=-1

# Print debugging messages (ON/OFF)
Debug.Messages = ON
